% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape_job.R
\name{scrape_job}
\alias{scrape_job}
\title{Start a scraping job}
\usage{
scrape_job(job_titles_index, experience_level_index, locations_index,
  sort = "R")
}
\arguments{
\item{job_titles_index}{The index of the job gtitle to search for from the job_titles data.frame (e.g., job_titles <- c('data scientist', 'data analyst', 'data engineer'))}

\item{experience_level_index}{The index of the experience level to search for from the experience_levels data.frame (e.g., experience_levels <- c(1, 2, 3))}

\item{locations_index}{The index of the experience level to search for from the locations data.frame (e.g., locations <- c(locations <- c('New York City Metropolitan Area', 'Greater Toronto Area Metropolitan Area'))}
}
\description{
This is the master scraping function. It will call \code{scrape()} to invoke
NodeJS puppeteer for scraping, and then move the files to the appropriate
directory structure.
}
\details{
Note that this function expects the data.frames defined in jobs_to_scrape.R to be initialized (job_titles, experience_levels, locations, job_titles_abbv, and locations_abbv).
}
